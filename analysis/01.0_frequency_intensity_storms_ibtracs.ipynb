{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing the frequency and intensity of storms in Myanmar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the scale used here: https://en.wikipedia.org/wiki/Tropical_cyclone_intensity_scales#North_Indian_Ocean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-29T13:03:56.392696Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_black\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-07-29T13:06:33.606748Z"
    }
   },
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import calendar\n",
    "from dotenv import load_dotenv\n",
    "from src.constants import *\n",
    "from src.codab import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T14:58:03.207943800Z",
     "start_time": "2025-07-25T13:30:08.350717Z"
    }
   },
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "'/vsizip/H:\\Shared drives\\Data Science\\CERF Anticipatory Action\\General - All AA projects\\Data\\public/raw/mmr/cod_ab/mmr_adm_250k_mimu_20240215_ab_shp.zip' does not exist in the file system, and is not recognized as a supported dataset name.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mDataSourceError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m load_dotenv()\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m gdf_adm = \u001B[43mload_codab\u001B[49m\u001B[43m(\u001B[49m\u001B[43madmin_level\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m ibtracs_path = Path(AA_DATA_DIR) / \u001B[33m\"\u001B[39m\u001B[33mpublic\u001B[39m\u001B[33m\"\u001B[39m / \u001B[33m\"\u001B[39m\u001B[33mraw\u001B[39m\u001B[33m\"\u001B[39m / \u001B[33m\"\u001B[39m\u001B[33mglb\u001B[39m\u001B[33m\"\u001B[39m / \u001B[33m\"\u001B[39m\u001B[33mibtracs\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m      4\u001B[39m points_path = Path(ibtracs_path / \u001B[33m\"\u001B[39m\u001B[33mIBTrACS.NI.list.v04r01.points.zip\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\ds-aa-mmr-cyclones\\src\\codab.py:14\u001B[39m, in \u001B[36mload_codab\u001B[39m\u001B[34m(admin_level)\u001B[39m\n\u001B[32m     10\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mOnly admin level 1 is supported\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     11\u001B[39m adm_path = os.path.join(AA_DATA_DIR,\n\u001B[32m     12\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mpublic/raw/mmr/cod_ab/mmr_adm_250k_mimu_20240215_ab_shp.zip\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     13\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m gdf = \u001B[43mgpd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43madm_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmmr_polbnda_adm\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43madmin_level\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m_250k_mimu_20240215\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m gdf\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\io\\file.py:294\u001B[39m, in \u001B[36m_read_file\u001B[39m\u001B[34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001B[39m\n\u001B[32m    291\u001B[39m             from_bytes = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m    293\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m engine == \u001B[33m\"\u001B[39m\u001B[33mpyogrio\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m294\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read_file_pyogrio\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrows\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m engine == \u001B[33m\"\u001B[39m\u001B[33mfiona\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    299\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m pd.api.types.is_file_like(filename):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\io\\file.py:547\u001B[39m, in \u001B[36m_read_file_pyogrio\u001B[39m\u001B[34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001B[39m\n\u001B[32m    538\u001B[39m     warnings.warn(\n\u001B[32m    539\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThe \u001B[39m\u001B[33m'\u001B[39m\u001B[33minclude_fields\u001B[39m\u001B[33m'\u001B[39m\u001B[33m and \u001B[39m\u001B[33m'\u001B[39m\u001B[33mignore_fields\u001B[39m\u001B[33m'\u001B[39m\u001B[33m keywords are deprecated, and \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    540\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mwill be removed in a future release. You can use the \u001B[39m\u001B[33m'\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m'\u001B[39m\u001B[33m keyword \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   (...)\u001B[39m\u001B[32m    543\u001B[39m         stacklevel=\u001B[32m3\u001B[39m,\n\u001B[32m    544\u001B[39m     )\n\u001B[32m    545\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mcolumns\u001B[39m\u001B[33m\"\u001B[39m] = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33minclude_fields\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m547\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpyogrio\u001B[49m\u001B[43m.\u001B[49m\u001B[43mread_dataframe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_bytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\geopandas.py:275\u001B[39m, in \u001B[36mread_dataframe\u001B[39m\u001B[34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001B[39m\n\u001B[32m    270\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m use_arrow:\n\u001B[32m    271\u001B[39m     \u001B[38;5;66;03m# For arrow, datetimes are read as is.\u001B[39;00m\n\u001B[32m    272\u001B[39m     \u001B[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001B[39;00m\n\u001B[32m    273\u001B[39m     \u001B[38;5;66;03m# as numpy does not directly support timezones.\u001B[39;00m\n\u001B[32m    274\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mdatetime_as_string\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m275\u001B[39m result = \u001B[43mread_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    276\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    277\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    278\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    279\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    280\u001B[39m \u001B[43m    \u001B[49m\u001B[43mread_geometry\u001B[49m\u001B[43m=\u001B[49m\u001B[43mread_geometry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    281\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_2d\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgdal_force_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    282\u001B[39m \u001B[43m    \u001B[49m\u001B[43mskip_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskip_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    283\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    284\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    285\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    286\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    287\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    288\u001B[39m \u001B[43m    \u001B[49m\u001B[43msql\u001B[49m\u001B[43m=\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    289\u001B[39m \u001B[43m    \u001B[49m\u001B[43msql_dialect\u001B[49m\u001B[43m=\u001B[49m\u001B[43msql_dialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    290\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_fids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfid_as_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    291\u001B[39m \u001B[43m    \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    292\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_arrow:\n\u001B[32m    295\u001B[39m     \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpyarrow\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpa\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyogrio\\raw.py:198\u001B[39m, in \u001B[36mread\u001B[39m\u001B[34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001B[39m\n\u001B[32m     59\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Read OGR data source into numpy arrays.\u001B[39;00m\n\u001B[32m     60\u001B[39m \n\u001B[32m     61\u001B[39m \u001B[33;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    194\u001B[39m \n\u001B[32m    195\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    196\u001B[39m dataset_kwargs = _preprocess_options_key_value(kwargs) \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;28;01melse\u001B[39;00m {}\n\u001B[32m--> \u001B[39m\u001B[32m198\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mogr_read\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    199\u001B[39m \u001B[43m    \u001B[49m\u001B[43mget_vsi_path_or_buffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_buffer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    200\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlayer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    201\u001B[39m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    202\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    203\u001B[39m \u001B[43m    \u001B[49m\u001B[43mread_geometry\u001B[49m\u001B[43m=\u001B[49m\u001B[43mread_geometry\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    204\u001B[39m \u001B[43m    \u001B[49m\u001B[43mforce_2d\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    205\u001B[39m \u001B[43m    \u001B[49m\u001B[43mskip_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mskip_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    206\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmax_features\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmax_features\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    207\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m=\u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    208\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbbox\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    209\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmask\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_mask_to_wkb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    210\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    211\u001B[39m \u001B[43m    \u001B[49m\u001B[43msql\u001B[49m\u001B[43m=\u001B[49m\u001B[43msql\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    212\u001B[39m \u001B[43m    \u001B[49m\u001B[43msql_dialect\u001B[49m\u001B[43m=\u001B[49m\u001B[43msql_dialect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    213\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_fids\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_fids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdataset_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdataset_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    215\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdatetime_as_string\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdatetime_as_string\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    216\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpyogrio\\\\_io.pyx:1293\u001B[39m, in \u001B[36mpyogrio._io.ogr_read\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpyogrio\\\\_io.pyx:232\u001B[39m, in \u001B[36mpyogrio._io.ogr_open\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mDataSourceError\u001B[39m: '/vsizip/H:\\Shared drives\\Data Science\\CERF Anticipatory Action\\General - All AA projects\\Data\\public/raw/mmr/cod_ab/mmr_adm_250k_mimu_20240215_ab_shp.zip' does not exist in the file system, and is not recognized as a supported dataset name."
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "gdf_adm = load_codab(admin_level=0)\n",
    "ibtracs_path = Path(AA_DATA_DIR) / \"public\" / \"raw\" / \"glb\" / \"ibtracs\"\n",
    "points_path = Path(ibtracs_path / \"IBTrACS.NI.list.v04r01.points.zip\")\n",
    "\n",
    "gdf_points = gpd.read_file(points_path, layer=\"IBTrACS.NI.list.v04r01.points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at which months cyclones happen in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_points_1980 = gdf_points[gdf_points[\"year\"] >= 1980]\n",
    "gdf_points_1980[[\"NAME\", \"NEW_WIND\"]]  # it seems some values are missing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in missing values with those from USA and converting 1-minute to 3-minute winds.\n",
    "gdf_points_1980.loc[:, \"NEW_USA_WIND\"] = gdf_points_1980[\"NEW_WIND\"].fillna(\n",
    "    gdf_points_1980[\"USA_WIND\"] * 0.93\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_buffer = 0  # Use 0, 50 or 100: these are in km\n",
    "gdf_adm_projected = gdf_adm.to_crs(epsg=MMR_UTM)\n",
    "gdf_adm_projected[\"geometry\"] = gdf_adm_projected.geometry.buffer(\n",
    "    adm_buffer * 1000\n",
    ")\n",
    "gdf_adm_buffered = gdf_adm_projected.to_crs(gdf_adm.crs)\n",
    "gdf_points_adm = gpd.sjoin(\n",
    "    gdf_points_1980, gdf_adm_buffered, how=\"inner\", predicate=\"intersects\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gdf_adm.plot(color=\"lightblue\", edgecolor=\"black\", alpha=0.3)\n",
    "gdf_points_adm.plot(ax=ax, column=\"NEW_USA_WIND\", markersize=10, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_counts = gdf_points_adm.groupby(\"month\")[\"SID\"].nunique()\n",
    "\n",
    "total_storms = gdf_points_adm[\"SID\"].nunique()\n",
    "month_percent = (month_counts / total_storms) * 100\n",
    "\n",
    "month_labels = [calendar.month_name[m] for m in month_counts.index]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "month_percent.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Percentage of Total Storms (%)\")\n",
    "plt.title(f\"Percentage of Storms by Month - Buffer: {adm_buffer}km\")\n",
    "plt.xticks(ticks=range(len(month_labels)), labels=month_labels, rotation=45)\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at frequency of different intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 16, 27, 33, 47, 63, 89, 119, float(\"inf\")]\n",
    "labels = [\n",
    "    \"Below Depression\",\n",
    "    \"Depression\",\n",
    "    \"Deep Depression\",\n",
    "    \"Cyclonic Storm\",\n",
    "    \"Severe Cyclonic Storm\",\n",
    "    \"Very Severe Cyclonic Storm\",\n",
    "    \"Extremely Severe Cyclonic Storm\",\n",
    "    \"Super Cyclonic Storm\",\n",
    "]\n",
    "gdf_points_adm[\"IMD_SCALE\"] = pd.cut(\n",
    "    gdf_points_adm[\"NEW_USA_WIND\"], bins=bins, labels=labels, right=True\n",
    ")\n",
    "gdf_points_adm[[\"NEW_USA_WIND\", \"IMD_SCALE\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_year = gdf_points_adm[\"year\"].min()\n",
    "max_year = gdf_points_adm[\"year\"].max()\n",
    "total_years = max_year - min_year + 1\n",
    "intensity_counts = (\n",
    "    gdf_points_adm[\"IMD_SCALE\"].value_counts().reindex(labels, fill_value=0)\n",
    ")\n",
    "\n",
    "return_periods = total_years / intensity_counts.replace(0, float(\"inf\"))\n",
    "cumulative_counts = intensity_counts[::-1].cumsum()[::-1]\n",
    "return_periods_cumulative = total_years / cumulative_counts.replace(\n",
    "    0, float(\"inf\")\n",
    ")\n",
    "df_table = pd.DataFrame(\n",
    "    {\n",
    "        \"Cyclone Intensity Category\": labels,\n",
    "        \"Number of Observations\": intensity_counts.values,\n",
    "        \"Return Period (years)\": return_periods.round(1),\n",
    "        \"Return Period (â‰¥ Intensity) (years)\": return_periods_cumulative.round(\n",
    "            1\n",
    "        ),\n",
    "    }\n",
    ")\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.axis(\"tight\")\n",
    "ax.axis(\"off\")\n",
    "table = ax.table(\n",
    "    cellText=df_table.values,\n",
    "    colLabels=df_table.columns,\n",
    "    cellLoc=\"center\",\n",
    "    loc=\"center\",\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.auto_set_column_width([0, 1, 2, 3])\n",
    "\n",
    "plt.title(\n",
    "    f\"Cyclone Return Periods by Intensity (IMD Classification)\\nBased on {total_years} Years of Data ({min_year}-{max_year})\",\n",
    "    fontsize=12,\n",
    "    weight=\"bold\",\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
